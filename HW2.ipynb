{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.data import Dataset\n",
    "import glob\n",
    "import sys\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     1,
     6,
     14
    ]
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def get_img_array(path):\n",
    "    \"\"\"\n",
    "    Given path of image, returns it's numpy array\n",
    "    \"\"\"\n",
    "    return scipy.misc.imread(path)\n",
    "\n",
    "def get_files(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns list of files in it\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    filenames.sort()\n",
    "    return filenames\n",
    "\n",
    "def get_label(filepath, label2id):\n",
    "    \"\"\"\n",
    "    Files are assumed to be labeled as: /path/to/file/999_frog.png\n",
    "    Returns label for a filepath\n",
    "    \"\"\"\n",
    "    tokens = filepath.split('/')\n",
    "    label = tokens[-1].split('_')[1][:-4]\n",
    "    if label in label2id:\n",
    "        return label2id[label]\n",
    "    else:\n",
    "        sys.exit(\"Invalid label: \" + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     2,
     14,
     22,
     37,
     57,
     68
    ]
   },
   "outputs": [],
   "source": [
    "#functions to load data\n",
    "\n",
    "def get_labels(folder, label2id):\n",
    "    \"\"\"\n",
    "    Returns vector of labels extracted from filenames of all files in folder\n",
    "    :param folder: path to data folder\n",
    "    :param label2id: mapping of text labels to numeric ids. (Eg: automobile -> 0)\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    y = []\n",
    "    for f in files:\n",
    "        y.append(get_label(f,label2id))\n",
    "    return np.array(y)\n",
    "\n",
    "def one_hot(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts each label index in y to vector with one_hot encoding\n",
    "    \"\"\"\n",
    "    y_one_hot = np.zeros((num_classes, y.shape[0]))\n",
    "    y_one_hot[y, range(y.shape[0])] = 1\n",
    "    return y_one_hot\n",
    "\n",
    "def get_label_mapping(label_file):\n",
    "    \"\"\"\n",
    "    Returns mappings of label to index and index to label\n",
    "    The input file has list of labels, each on a separate line.\n",
    "    \"\"\"\n",
    "    with open(label_file, 'r') as f:\n",
    "        id2label = f.readlines()\n",
    "        id2label = [l.strip() for l in id2label]\n",
    "    label2id = {}\n",
    "    count = 0\n",
    "    for label in id2label:\n",
    "        label2id[label] = count\n",
    "        count += 1\n",
    "    return id2label, label2id\n",
    "\n",
    "def get_images(folder):\n",
    "    \"\"\"\n",
    "    returns numpy array of all samples in folder\n",
    "    each column is a sample resized to 30x30 and flattened\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    images = []\n",
    "    count = 0\n",
    "    \n",
    "    for f in files:\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print(\"Loaded {}/{}\".format(count,len(files)))\n",
    "        img_arr = get_img_array(f)\n",
    "        img_arr = img_arr.flatten() / 255.0\n",
    "        images.append(img_arr)\n",
    "    X = np.column_stack(images)\n",
    "\n",
    "    return X\n",
    "\n",
    "def get_train_data(data_root_path):\n",
    "    \"\"\"\n",
    "    Return X and y\n",
    "    \"\"\"\n",
    "    train_data_path = data_root_path + 'train'\n",
    "    id2label, label2id = get_label_mapping(data_root_path+'labels.txt')\n",
    "    print(label2id)\n",
    "    X = get_images(train_data_path)\n",
    "    y = get_labels(train_data_path, label2id)\n",
    "    return X, y\n",
    "\n",
    "def save_predictions(filename, y):\n",
    "    \"\"\"\n",
    "    Dumps y into .npy file\n",
    "    \"\"\"\n",
    "    np.save(filename, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'frog': 6, 'ship': 8, 'bird': 2, 'dog': 5, 'automobile': 1, 'truck': 9, 'cat': 3, 'horse': 7, 'deer': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000/50000\n",
      "Loaded 20000/50000\n",
      "Loaded 30000/50000\n",
      "Loaded 40000/50000\n",
      "Loaded 50000/50000\n",
      "(50000, 3072)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"cifar10-hw2/\"\n",
    "X_train, y_train = get_train_data(data_path)\n",
    "\n",
    "y_train = y_train.reshape(50000,)\n",
    "X_train = np.swapaxes(X_train,1,0)\n",
    "print(X_train.shape)\n",
    "X_train = np.asarray(X_train,dtype = np.float32)\n",
    "y_train = np.asarray(y_train,dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n",
      "(40000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#split into train and test segments\n",
    "X_test = X_train[-10000:,:]\n",
    "X_train = X_train[:40000]\n",
    "y_test = y_train[-10000:]\n",
    "y_train = y_train[:40000]\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = \"tmp/cifar-w_validation_data/\"\n",
    "tf.reset_default_graph()\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features,labels))\n",
    "    # step 3: parse every image in the dataset using `map`\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    print(dataset)\n",
    "    #dataset = dataset.batch(batch_size)\n",
    "\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    print((features,labels))\n",
    "\n",
    "    return features, labels\n",
    "\"\"\"\n",
    "def _parse_function(filename,label):\n",
    "    print(filename)\n",
    "    print(\"HELLO\")\n",
    "    image_string = tf.read_file(filename)\n",
    "    print(image_string)\n",
    "    image_decoded = tf.image.decode_png(image_string, channels=3)\n",
    "    image_decoded = tf.reshape(image_decoded, [3072])\n",
    "\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "    print(image)\n",
    "    label = tf.reshape(label, [1])\n",
    "    return image,label\"\"\"\n",
    "\n",
    "def my_model_fn(features, labels, mode, params): \n",
    "\n",
    "    input_layer = tf.reshape(features[\"x\"],[-1,32,32,3])\n",
    "    tf.summary.image(\"image\",input_layer,3)\n",
    "    with tf.name_scope(\"conv1\"):\n",
    "    #conv layer 1\n",
    "        conv1 = tf.layers.conv2d(\n",
    "          inputs=input_layer,\n",
    "          filters=32,\n",
    "          kernel_size=[5,5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu,\n",
    "          name = \"conv1\")\n",
    "        tf.summary.histogram(\"conv1\",conv1)\n",
    "        \n",
    "    #with tf.variable_scope(\"conv1\") as scope:\n",
    "        #tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "       # kernel = tf.get_variable('kernel')\n",
    "        \n",
    "        \"\"\"W1_a = kernel\n",
    "        W1pad= tf.zeros([5, 5, 3, 4]) # [5, 5, 3, 4]  - four zero kernels for padding\n",
    "        print(W1pad)\n",
    "        W1_b = tf.concat([W1pad,W1_a],3)   # [5, 5, 3, 36]\n",
    "        print(W1_b)\n",
    "        W1_c = tf.split(W1_b, 36, 3)         # 36 x [5, 5, 3, 1]\n",
    "        W1_row0 = tf.concat(W1_c[0:6], 0)    # [30, 5, 3, 1]\n",
    "        W1_row1 = tf.concat(W1_c[6:12],0)   # [30, 5, 3, 1]\n",
    "        W1_row2 = tf.concat(W1_c[12:18],0)  # [30, 5, 3, 1]\n",
    "        W1_row3 = tf.concat(W1_c[18:24],0)  # [30, 5, 3, 1]\n",
    "        W1_row4 = tf.concat(W1_c[24:30],0)  # [30, 5, 3, 1]\n",
    "        W1_row5 = tf.concat(W1_c[30:36],0)  # [30, 5, 3, 1]\n",
    "        W1_d = tf.concat([W1_row0, W1_row1, W1_row2, W1_row3, W1_row4, W1_row5],1) # [30, 30, 3, 1]\n",
    "        W1_e = tf.reshape(W1_d, [1, 30, 30, 3])\n",
    "        Wtag = tf.placeholder(tf.string, None)\n",
    "        #tf.image_summary(Wtag, W1_e)\n",
    "        tf.summary.image(Wtag,W1_e)\"\"\"\n",
    "\n",
    "        \n",
    "    with tf.name_scope(\"pool1\"):\n",
    "        #pooling layer 1\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size = [2,2],strides = 2)\n",
    "        tf.summary.histogram(\"pool1\",pool1)\n",
    "        \n",
    "    #Convolutional Layer #2 and Pooling Layer #2\n",
    "    with tf.name_scope(\"conv2\"):\n",
    "        conv2 = tf.layers.conv2d(inputs = pool1, filters = 64, kernel_size = [5,5],\n",
    "                                 padding = 'same', activation = tf.nn.relu)\n",
    "        tf.summary.histogram(\"conv2\",conv2)\n",
    "        \n",
    "    with tf.name_scope(\"pool2\"):\n",
    "        pool2 = tf.layers.max_pooling2d(inputs = conv2, pool_size=[2,2],strides = 2)\n",
    "        tf.summary.histogram(\"pool2\",pool2)\n",
    "        \n",
    "    with tf.name_scope(\"pool2_flat\"):\n",
    "        #dense layer\n",
    "        pool2_flat = tf.reshape(pool2, [-1, 8*8*64])\n",
    "        tf.summary.histogram(\"pool2_flat\",pool2_flat)\n",
    "        \n",
    "    with tf.name_scope(\"dense\"):\n",
    "        dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "        tf.summary.histogram(\"dense\",dense)\n",
    "    \n",
    "    with tf.name_scope(\"dropout\"):\n",
    "        dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        tf.summary.histogram(\"dropout\",dropout)\n",
    "        \n",
    "    with tf.name_scope(\"logits\"):\n",
    "        logits = tf.layers.dense(inputs = dropout, units = 10)\n",
    "        tf.summary.histogram(\"logits\",logits)\n",
    "    \n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\" : tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\" : tf.nn.softmax(logits,name = \"softmax_tensor\")\n",
    "        }\n",
    "    \n",
    "    with tf.name_scope(\"train-accuracy\"):\n",
    "        train_prediction = tf.nn.softmax(logits)\n",
    "        #train_prediction = tf.cast(train_prediction, tf.int64)\n",
    "        cast_labels = tf.cast(labels,tf.int64)\n",
    "        correct_prediction = tf.equal(tf.argmax(train_prediction, 1), cast_labels)\n",
    "      \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"train-accuracy\", accuracy)\n",
    "\n",
    "    \n",
    "    if(mode == tf.estimator.ModeKeys.PREDICT):\n",
    "        predictions = {\n",
    "        \"classes\" : tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\" : tf.nn.softmax(logits,name = \"softmax_tensor\")\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, predictions=predictions)\n",
    "\n",
    "\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            \"accuracy\": tf.metrics.accuracy(\n",
    "                labels=labels, predictions=predictions[\"classes\"])}\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "\n",
    "        train_op = optimizer.minimize(loss = loss, global_step = tf.train.get_global_step())\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "\n",
    "    \n",
    "    summ = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOGDIR)\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_save_summary_steps': 100, '_task_id': 0, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_is_chief': True, '_session_config': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_service': None, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f607ba17ac8>, '_task_type': 'worker', '_model_dir': 'tmp/cifar-w_validation_data/', '_master': ''}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tmp/cifar-w_validation_data/model.ckpt-150343\n",
      "INFO:tensorflow:Saving checkpoints for 150344 into tmp/cifar-w_validation_data/model.ckpt.\n",
      "INFO:tensorflow:step = 150344, loss = 0.5265207\n",
      "INFO:tensorflow:global_step/sec: 38.0635\n",
      "INFO:tensorflow:step = 150444, loss = 0.43639228 (2.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.699\n",
      "INFO:tensorflow:step = 150544, loss = 0.5690039 (2.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6271\n",
      "INFO:tensorflow:step = 150644, loss = 0.5632918 (3.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.3563\n",
      "INFO:tensorflow:step = 150744, loss = 0.43976092 (2.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7887\n",
      "INFO:tensorflow:step = 150844, loss = 0.39174154 (2.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.784\n",
      "INFO:tensorflow:step = 150944, loss = 0.40432376 (2.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7367\n",
      "INFO:tensorflow:step = 151044, loss = 0.38232347 (2.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.9098\n",
      "INFO:tensorflow:step = 151144, loss = 0.45654523 (2.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5205\n",
      "INFO:tensorflow:step = 151244, loss = 0.5939418 (2.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.528\n",
      "INFO:tensorflow:step = 151344, loss = 0.36676782 (2.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.4453\n",
      "INFO:tensorflow:step = 151444, loss = 0.5918802 (3.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.503\n",
      "INFO:tensorflow:step = 151544, loss = 0.5330714 (3.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.5133\n",
      "INFO:tensorflow:step = 151644, loss = 0.43716308 (3.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.734\n",
      "INFO:tensorflow:step = 151744, loss = 0.51893383 (2.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.5092\n",
      "INFO:tensorflow:step = 151844, loss = 0.3875051 (2.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.14\n",
      "INFO:tensorflow:step = 151944, loss = 0.46226522 (2.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.3012\n",
      "INFO:tensorflow:step = 152044, loss = 0.45938948 (2.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7488\n",
      "INFO:tensorflow:step = 152144, loss = 0.5641501 (2.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7344\n",
      "INFO:tensorflow:step = 152244, loss = 0.44350013 (2.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.2896\n",
      "INFO:tensorflow:step = 152344, loss = 0.41974652 (2.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0922\n",
      "INFO:tensorflow:step = 152444, loss = 0.42474017 (3.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4229\n",
      "INFO:tensorflow:step = 152544, loss = 0.4957155 (3.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8898\n",
      "INFO:tensorflow:step = 152644, loss = 0.42483214 (3.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.4596\n",
      "INFO:tensorflow:step = 152744, loss = 0.4711374 (3.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4368\n",
      "INFO:tensorflow:step = 152844, loss = 0.54946154 (3.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0416\n",
      "INFO:tensorflow:step = 152944, loss = 0.5177697 (2.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.1981\n",
      "INFO:tensorflow:step = 153044, loss = 0.5605305 (3.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0179\n",
      "INFO:tensorflow:step = 153144, loss = 0.5417197 (2.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.7006\n",
      "INFO:tensorflow:step = 153244, loss = 0.69602865 (3.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2432\n",
      "INFO:tensorflow:step = 153344, loss = 0.43314788 (3.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.8552\n",
      "INFO:tensorflow:step = 153444, loss = 0.5170418 (2.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0521\n",
      "INFO:tensorflow:step = 153544, loss = 0.3682811 (2.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.9612\n",
      "INFO:tensorflow:step = 153644, loss = 0.44734424 (2.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.9072\n",
      "INFO:tensorflow:step = 153744, loss = 0.65957963 (2.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3669\n",
      "INFO:tensorflow:step = 153844, loss = 0.43809488 (3.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0678\n",
      "INFO:tensorflow:step = 153944, loss = 0.4739347 (2.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3618\n",
      "INFO:tensorflow:step = 154044, loss = 0.27349025 (2.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3425\n",
      "INFO:tensorflow:step = 154144, loss = 0.514621 (2.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2389\n",
      "INFO:tensorflow:step = 154244, loss = 0.38715437 (2.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3597\n",
      "INFO:tensorflow:step = 154344, loss = 0.35707965 (2.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3247\n",
      "INFO:tensorflow:step = 154444, loss = 0.38283485 (2.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2494\n",
      "INFO:tensorflow:step = 154544, loss = 0.4463689 (2.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.9243\n",
      "INFO:tensorflow:step = 154644, loss = 0.55799973 (3.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.7655\n",
      "INFO:tensorflow:step = 154744, loss = 0.3550351 (3.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5054\n",
      "INFO:tensorflow:step = 154844, loss = 0.52546686 (3.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3735\n",
      "INFO:tensorflow:step = 154944, loss = 0.5515977 (3.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8519\n",
      "INFO:tensorflow:step = 155044, loss = 0.63034844 (3.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.6945\n",
      "INFO:tensorflow:step = 155144, loss = 0.51651037 (3.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4267\n",
      "INFO:tensorflow:step = 155244, loss = 0.4387839 (3.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.9876\n",
      "INFO:tensorflow:step = 155344, loss = 0.43329212 (3.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.9336\n",
      "INFO:tensorflow:step = 155444, loss = 0.47094196 (3.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7147\n",
      "INFO:tensorflow:step = 155544, loss = 0.36631477 (3.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.757\n",
      "INFO:tensorflow:step = 155644, loss = 0.4567035 (3.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.787\n",
      "INFO:tensorflow:step = 155744, loss = 0.47920477 (3.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4285\n",
      "INFO:tensorflow:step = 155844, loss = 0.3744401 (3.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.9179\n",
      "INFO:tensorflow:step = 155944, loss = 0.48242864 (3.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1879\n",
      "INFO:tensorflow:step = 156044, loss = 0.34104395 (3.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.5379\n",
      "INFO:tensorflow:step = 156144, loss = 0.41707835 (2.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.6113\n",
      "INFO:tensorflow:step = 156244, loss = 0.40871394 (2.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3449\n",
      "INFO:tensorflow:step = 156344, loss = 0.46758968 (2.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2718\n",
      "INFO:tensorflow:step = 156444, loss = 0.5000595 (2.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0122\n",
      "INFO:tensorflow:step = 156544, loss = 0.43551964 (2.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2169\n",
      "INFO:tensorflow:step = 156644, loss = 0.4113377 (2.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.2055\n",
      "INFO:tensorflow:step = 156744, loss = 0.47003394 (3.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.6352\n",
      "INFO:tensorflow:step = 156844, loss = 0.4371737 (2.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.1903\n",
      "INFO:tensorflow:step = 156944, loss = 0.3799202 (3.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.442\n",
      "INFO:tensorflow:step = 157044, loss = 0.5836169 (5.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.041\n",
      "INFO:tensorflow:step = 157144, loss = 0.45358604 (3.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0901\n",
      "INFO:tensorflow:step = 157244, loss = 0.36969188 (3.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8815\n",
      "INFO:tensorflow:step = 157344, loss = 0.5257132 (3.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.183\n",
      "INFO:tensorflow:step = 157444, loss = 0.49644434 (2.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.2298\n",
      "INFO:tensorflow:step = 157544, loss = 0.38934082 (3.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 157644, loss = 0.4332565 (2.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.5933\n",
      "INFO:tensorflow:step = 157744, loss = 0.42717406 (3.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8726\n",
      "INFO:tensorflow:step = 157844, loss = 0.5066179 (3.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0102\n",
      "INFO:tensorflow:step = 157944, loss = 0.4317413 (3.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4112\n",
      "INFO:tensorflow:step = 158044, loss = 0.39960045 (3.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2716\n",
      "INFO:tensorflow:step = 158144, loss = 0.38132858 (3.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.2685\n",
      "INFO:tensorflow:step = 158244, loss = 0.5367272 (3.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.9105\n",
      "INFO:tensorflow:step = 158344, loss = 0.32594842 (2.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1552\n",
      "INFO:tensorflow:step = 158444, loss = 0.39563864 (3.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1101\n",
      "INFO:tensorflow:step = 158544, loss = 0.30216426 (3.683 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-3c902bd6a349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    537\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1011\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1014\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1159\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[3072], dtype=tf.float32)]\n",
    "tf.reset_default_graph()\n",
    "#set up classifier\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn = my_model_fn,\n",
    "    model_dir = LOGDIR,\n",
    "    params={\n",
    "        'feature_columns' : feature_columns,\n",
    "        #choose between 10 classes\n",
    "        'n_classes':10,\n",
    "    }\n",
    ")\n",
    "#tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "#logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\":X_train},\n",
    "    y = y_train,\n",
    "    batch_size = 100,\n",
    "    num_epochs = None,\n",
    "    shuffle = True\n",
    "    )\n",
    "classifier.train(input_fn=train_input_fn, steps = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-25-02:17:17\n",
      "INFO:tensorflow:Restoring parameters from tmp/cifar-w_validation_data/model.ckpt-150344\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-25-02:17:19\n",
      "INFO:tensorflow:Saving dict for global step 150344: accuracy = 0.0975, global_step = 150344, loss = 6.9776187\n",
      "{'loss': 6.9776187, 'accuracy': 0.0975, 'global_step': 150344}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": X_test},\n",
    "  y=y_test,\n",
    "  num_epochs=1,\n",
    "  shuffle=False)\n",
    "eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000/10000\n",
      "(10000, 3072)\n",
      "<generator object Estimator.predict at 0x7f607b2eb830>\n"
     ]
    }
   ],
   "source": [
    "X_test = get_images('cifar10-hw2/test')\n",
    "X_test = X_test.T\n",
    "X_test = np.asarray(X_test,np.float32)\n",
    "print(X_test.shape)\n",
    "y_test = ['airplane', 'frog', 'ship', 'bird', 'dog',\n",
    "         'automobile', 'truck', 'cat', 'horse', 'deer']\n",
    "y_test = np.asarray(y_test)\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"x\" : X_test},\n",
    "    y = None,\n",
    "    shuffle = False\n",
    "    \n",
    "    )\n",
    "preds = classifier.predict(input_fn = predict_input_fn)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
